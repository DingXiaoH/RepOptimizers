# RepOptimizers

This is the official repository of [Re-parameterizing Your Optimizers rather than Architectures](https://arxiv.org/abs/2205.15242).

If you find the paper or this repository helpful, please consider citing

        @article{ding2022re,
        title={Re-parameterizing Your Optimizers rather than Architectures},
        author={Ding, Xiaohan and Chen, Honghao and Zhang, Xiangyu and Huang, Kaiqi and Han, Jungong and Ding, Guiguang},
        journal={arXiv preprint arXiv:2205.15242},
        year={2022}
        }

## Catalog
- [x] Model code
- [ ] PyTorch pretrained models
- [ ] PyTorch training code

<!-- ✅ ⬜️  -->

## Pre-trained Models




## Evaluation


## Training

### Hyper-Search on CIFAR-100

### Train the target model on ImageNet


## License
This project is released under the MIT license. Please see the [LICENSE](LICENSE) file for more information.

